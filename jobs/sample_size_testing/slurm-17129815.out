-----<sample size - ucf - gdt>-----
==============================   SLURM   ==============================
SLURM_MPI_TYPE                : pmix_v3
SLURM_NODEID                  : 0
SLURM_TASK_PID                : 2909402
SLURM_PRIO_PROCESS            : 0
SLURM_SUBMIT_DIR              : /lustre06/project/6061875/sdastani/SSL_video/jobs/sample_size_testing
SLURM_CPUS_PER_TASK           : 1
SLURM_PROCID                  : 0
SLURM_JOB_GID                 : 3121684
SLURMD_NODENAME               : ng20202
RSNT_SLURM_MPI_TYPE           : pmix_v3
SLURM_TASKS_PER_NODE          : 1
SLURM_NNODES                  : 1
SLURM_TMPDIR                  : /localscratch/sdastani.17129815.0
SLURM_NTASKS_PER_NODE         : 1
SLURM_JOB_NODELIST            : ng20202
SLURM_CLUSTER_NAME            : narval
SLURM_NODELIST                : ng20202
SLURM_GPUS_ON_NODE            : 1
SLURM_NTASKS                  : 1
SLURM_JOB_CPUS_PER_NODE       : 1
SLURM_TOPOLOGY_ADDR           : ihpc207u29.ihpc202u25.ng20202
SLURM_WORKING_CLUSTER         : narval:10.100.129.45:6817:9728:109
SLURM_JOB_NAME                : brats
SLURM_JOB_GPUS                : 1
SLURM_JOBID                   : 17129815
SLURM_CONF                    : /etc/slurm/slurm.conf
SLURM_NODE_ALIASES            : (null)
SLURM_JOB_QOS                 : normal
SLURM_TOPOLOGY_ADDR_PATTERN   : switch.switch.node
SLURM_CPUS_ON_NODE            : 1
SLURM_JOB_NUM_NODES           : 1
SLURM_MEM_PER_NODE            : 32768
SLURM_JOB_UID                 : 3121684
SLURM_JOB_PARTITION           : gpubase_bygpu_b3
SLURM_SCRIPT_CONTEXT          : prolog_task
SLURM_JOB_USER                : sdastani
SLURM_NPROCS                  : 1
SLURM_SUBMIT_HOST             : narval1.narval.calcul.quebec
SLURM_JOB_ACCOUNT             : rrg-ebrahimi_gpu
SLURM_GTIDS                   : 0
SLURM_RESTART_COUNT           : 0
SLURM_JOB_ID                  : 17129815
SLURM_LOCALID                 : 0
==============================   Config   ==============================
required_devices: 8
resume: False
no_test: False
test_only: False
debug: False
seed: 0
distributed: False
test_freq: 5
num_workers: 20
benchmark
  name: ucf101-full_finetune_1000_examples
dataset
  name: ucf101
  fold: 1
  batch_size: 32
  clip_duration: 2.0
  video_fps: 16.0
  crop_size: 112
  transform: msc+color
  min_area: 0.08
  normalize: True
  switch_channels: False
  num_of_examples: 1000
  color: [0.4, 0.4, 0.4, 0.2]
  train
    split: trainlist{fold:02d}
    mode: clip
    clips_per_video: 10
    use_augmentation: True
    use_shuffle: True
    drop_last: True
  test
    split: testlist{fold:02d}
    mode: clip
    clips_per_video: 5
    use_augmentation: False
    use_shuffle: False
    drop_last: False
  test_dense
    split: testlist{fold:02d}
    mode: video
    clips_per_video: 10
    use_augmentation: False
    use_shuffle: False
    drop_last: False
optimizer
  name: adam
  num_epochs: 16
  weight_decay: 0.0
  warmup_classifier: False
  lr
    name: multistep
    base_lr: 0.0001
    gamma: 0.3
    milestones: [6, 10, 14]
model
  args
    n_classes: 101
    feat_dim: 512
:::::::::::::::::::::::::::::::::::::::::::::::::::::::::: Loading gdt checkpoint ::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
Checkpoint Path: ../checkpoints_pretraining/gdt/gdt_K400.pth
Checkpoint Message: _IncompatibleKeys(missing_keys=['fc.weight', 'fc.bias'], unexpected_keys=['mlp_v.block_forward.2.weight', 'mlp_v.block_forward.4.weight', 'mlp_v.block_forward.4.bias', 'mlp_v.block_forward.4.running_mean', 'mlp_v.block_forward.4.running_var', 'mlp_v.block_forward.4.num_batches_tracked', 'mlp_v.block_forward.8.weight', 'mlp_v.block_forward.8.bias'])
==============================   Parameters   ==============================
stem.0.weight                                                          | Trainable  | 45 x 3 x 1 x 7 x 7             | 6615
stem.1.weight                                                          | Trainable  | 45                             | 45
stem.1.bias                                                            | Trainable  | 45                             | 45
stem.3.weight                                                          | Trainable  | 64 x 45 x 3 x 1 x 1            | 8640
stem.4.weight                                                          | Trainable  | 64                             | 64
stem.4.bias                                                            | Trainable  | 64                             | 64
layer1.0.conv1.0.0.weight                                              | Trainable  | 144 x 64 x 1 x 3 x 3           | 82944
layer1.0.conv1.0.1.weight                                              | Trainable  | 144                            | 144
layer1.0.conv1.0.1.bias                                                | Trainable  | 144                            | 144
layer1.0.conv1.0.3.weight                                              | Trainable  | 64 x 144 x 3 x 1 x 1           | 27648
layer1.0.conv1.1.weight                                                | Trainable  | 64                             | 64
layer1.0.conv1.1.bias                                                  | Trainable  | 64                             | 64
layer1.0.conv2.0.0.weight                                              | Trainable  | 144 x 64 x 1 x 3 x 3           | 82944
layer1.0.conv2.0.1.weight                                              | Trainable  | 144                            | 144
layer1.0.conv2.0.1.bias                                                | Trainable  | 144                            | 144
layer1.0.conv2.0.3.weight                                              | Trainable  | 64 x 144 x 3 x 1 x 1           | 27648
layer1.0.conv2.1.weight                                                | Trainable  | 64                             | 64
layer1.0.conv2.1.bias                                                  | Trainable  | 64                             | 64
layer1.1.conv1.0.0.weight                                              | Trainable  | 144 x 64 x 1 x 3 x 3           | 82944
layer1.1.conv1.0.1.weight                                              | Trainable  | 144                            | 144
layer1.1.conv1.0.1.bias                                                | Trainable  | 144                            | 144
layer1.1.conv1.0.3.weight                                              | Trainable  | 64 x 144 x 3 x 1 x 1           | 27648
layer1.1.conv1.1.weight                                                | Trainable  | 64                             | 64
layer1.1.conv1.1.bias                                                  | Trainable  | 64                             | 64
layer1.1.conv2.0.0.weight                                              | Trainable  | 144 x 64 x 1 x 3 x 3           | 82944
layer1.1.conv2.0.1.weight                                              | Trainable  | 144                            | 144
layer1.1.conv2.0.1.bias                                                | Trainable  | 144                            | 144
layer1.1.conv2.0.3.weight                                              | Trainable  | 64 x 144 x 3 x 1 x 1           | 27648
layer1.1.conv2.1.weight                                                | Trainable  | 64                             | 64
layer1.1.conv2.1.bias                                                  | Trainable  | 64                             | 64
layer2.0.conv1.0.0.weight                                              | Trainable  | 230 x 64 x 1 x 3 x 3           | 132480
layer2.0.conv1.0.1.weight                                              | Trainable  | 230                            | 230
layer2.0.conv1.0.1.bias                                                | Trainable  | 230                            | 230
layer2.0.conv1.0.3.weight                                              | Trainable  | 128 x 230 x 3 x 1 x 1          | 88320
layer2.0.conv1.1.weight                                                | Trainable  | 128                            | 128
layer2.0.conv1.1.bias                                                  | Trainable  | 128                            | 128
layer2.0.conv2.0.0.weight                                              | Trainable  | 230 x 128 x 1 x 3 x 3          | 264960
layer2.0.conv2.0.1.weight                                              | Trainable  | 230                            | 230
layer2.0.conv2.0.1.bias                                                | Trainable  | 230                            | 230
layer2.0.conv2.0.3.weight                                              | Trainable  | 128 x 230 x 3 x 1 x 1          | 88320
layer2.0.conv2.1.weight                                                | Trainable  | 128                            | 128
layer2.0.conv2.1.bias                                                  | Trainable  | 128                            | 128
layer2.0.downsample.0.weight                                           | Trainable  | 128 x 64 x 1 x 1 x 1           | 8192
layer2.0.downsample.1.weight                                           | Trainable  | 128                            | 128
layer2.0.downsample.1.bias                                             | Trainable  | 128                            | 128
layer2.1.conv1.0.0.weight                                              | Trainable  | 288 x 128 x 1 x 3 x 3          | 331776
layer2.1.conv1.0.1.weight                                              | Trainable  | 288                            | 288
layer2.1.conv1.0.1.bias                                                | Trainable  | 288                            | 288
layer2.1.conv1.0.3.weight                                              | Trainable  | 128 x 288 x 3 x 1 x 1          | 110592
layer2.1.conv1.1.weight                                                | Trainable  | 128                            | 128
layer2.1.conv1.1.bias                                                  | Trainable  | 128                            | 128
layer2.1.conv2.0.0.weight                                              | Trainable  | 288 x 128 x 1 x 3 x 3          | 331776
layer2.1.conv2.0.1.weight                                              | Trainable  | 288                            | 288
layer2.1.conv2.0.1.bias                                                | Trainable  | 288                            | 288
layer2.1.conv2.0.3.weight                                              | Trainable  | 128 x 288 x 3 x 1 x 1          | 110592
layer2.1.conv2.1.weight                                                | Trainable  | 128                            | 128
layer2.1.conv2.1.bias                                                  | Trainable  | 128                            | 128
layer3.0.conv1.0.0.weight                                              | Trainable  | 460 x 128 x 1 x 3 x 3          | 529920
layer3.0.conv1.0.1.weight                                              | Trainable  | 460                            | 460
layer3.0.conv1.0.1.bias                                                | Trainable  | 460                            | 460
layer3.0.conv1.0.3.weight                                              | Trainable  | 256 x 460 x 3 x 1 x 1          | 353280
layer3.0.conv1.1.weight                                                | Trainable  | 256                            | 256
layer3.0.conv1.1.bias                                                  | Trainable  | 256                            | 256
layer3.0.conv2.0.0.weight                                              | Trainable  | 460 x 256 x 1 x 3 x 3          | 1059840
layer3.0.conv2.0.1.weight                                              | Trainable  | 460                            | 460
layer3.0.conv2.0.1.bias                                                | Trainable  | 460                            | 460
layer3.0.conv2.0.3.weight                                              | Trainable  | 256 x 460 x 3 x 1 x 1          | 353280
layer3.0.conv2.1.weight                                                | Trainable  | 256                            | 256
layer3.0.conv2.1.bias                                                  | Trainable  | 256                            | 256
layer3.0.downsample.0.weight                                           | Trainable  | 256 x 128 x 1 x 1 x 1          | 32768
layer3.0.downsample.1.weight                                           | Trainable  | 256                            | 256
layer3.0.downsample.1.bias                                             | Trainable  | 256                            | 256
layer3.1.conv1.0.0.weight                                              | Trainable  | 576 x 256 x 1 x 3 x 3          | 1327104
layer3.1.conv1.0.1.weight                                              | Trainable  | 576                            | 576
layer3.1.conv1.0.1.bias                                                | Trainable  | 576                            | 576
layer3.1.conv1.0.3.weight                                              | Trainable  | 256 x 576 x 3 x 1 x 1          | 442368
layer3.1.conv1.1.weight                                                | Trainable  | 256                            | 256
layer3.1.conv1.1.bias                                                  | Trainable  | 256                            | 256
layer3.1.conv2.0.0.weight                                              | Trainable  | 576 x 256 x 1 x 3 x 3          | 1327104
layer3.1.conv2.0.1.weight                                              | Trainable  | 576                            | 576
layer3.1.conv2.0.1.bias                                                | Trainable  | 576                            | 576
layer3.1.conv2.0.3.weight                                              | Trainable  | 256 x 576 x 3 x 1 x 1          | 442368
layer3.1.conv2.1.weight                                                | Trainable  | 256                            | 256
layer3.1.conv2.1.bias                                                  | Trainable  | 256                            | 256
layer4.0.conv1.0.0.weight                                              | Trainable  | 921 x 256 x 1 x 3 x 3          | 2121984
layer4.0.conv1.0.1.weight                                              | Trainable  | 921                            | 921
layer4.0.conv1.0.1.bias                                                | Trainable  | 921                            | 921
layer4.0.conv1.0.3.weight                                              | Trainable  | 512 x 921 x 3 x 1 x 1          | 1414656
layer4.0.conv1.1.weight                                                | Trainable  | 512                            | 512
layer4.0.conv1.1.bias                                                  | Trainable  | 512                            | 512
layer4.0.conv2.0.0.weight                                              | Trainable  | 921 x 512 x 1 x 3 x 3          | 4243968
layer4.0.conv2.0.1.weight                                              | Trainable  | 921                            | 921
layer4.0.conv2.0.1.bias                                                | Trainable  | 921                            | 921
layer4.0.conv2.0.3.weight                                              | Trainable  | 512 x 921 x 3 x 1 x 1          | 1414656
layer4.0.conv2.1.weight                                                | Trainable  | 512                            | 512
layer4.0.conv2.1.bias                                                  | Trainable  | 512                            | 512
layer4.0.downsample.0.weight                                           | Trainable  | 512 x 256 x 1 x 1 x 1          | 131072
layer4.0.downsample.1.weight                                           | Trainable  | 512                            | 512
layer4.0.downsample.1.bias                                             | Trainable  | 512                            | 512
layer4.1.conv1.0.0.weight                                              | Trainable  | 1152 x 512 x 1 x 3 x 3         | 5308416
layer4.1.conv1.0.1.weight                                              | Trainable  | 1152                           | 1152
layer4.1.conv1.0.1.bias                                                | Trainable  | 1152                           | 1152
layer4.1.conv1.0.3.weight                                              | Trainable  | 512 x 1152 x 3 x 1 x 1         | 1769472
layer4.1.conv1.1.weight                                                | Trainable  | 512                            | 512
layer4.1.conv1.1.bias                                                  | Trainable  | 512                            | 512
layer4.1.conv2.0.0.weight                                              | Trainable  | 1152 x 512 x 1 x 3 x 3         | 5308416
layer4.1.conv2.0.1.weight                                              | Trainable  | 1152                           | 1152
layer4.1.conv2.0.1.bias                                                | Trainable  | 1152                           | 1152
layer4.1.conv2.0.3.weight                                              | Trainable  | 512 x 1152 x 3 x 1 x 1         | 1769472
layer4.1.conv2.1.weight                                                | Trainable  | 512                            | 512
layer4.1.conv2.1.bias                                                  | Trainable  | 512                            | 512
fc.weight                                                              | Trainable  | 101 x 512                      | 51712
fc.bias                                                                | Trainable  | 101                            | 101

config {'name': 'adam', 'num_epochs': 16, 'weight_decay': 0.0, 'warmup_classifier': False, 'lr': {'name': 'multistep', 'base_lr': 0.0001, 'gamma': 0.3, 'milestones': [6, 10, 14]}}
==============================   Train DB   ==============================
original data length 9537
subset data 10 1000
1010 1010
False
UCF-101
 - Root: /home/sdastani/scratch/datasets/ucf101
 - Subset: trainlist01
 - Num videos: 1010
 - Num samples: 10100
 - Example video: /home/sdastani/scratch/datasets/ucf101/ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c03.avi

==============================   Test DB   ==============================
False
UCF-101
 - Root: /home/sdastani/scratch/datasets/ucf101
 - Subset: testlist01
 - Num videos: 3783
 - Num samples: 18915
 - Example video: /home/sdastani/scratch/datasets/ucf101/ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi

==============================   Dense DB   ==============================
False
UCF-101
 - Root: /home/sdastani/scratch/datasets/ucf101
 - Subset: testlist01
 - Num videos: 3783
 - Num samples: 37830
 - Example video: /home/sdastani/scratch/datasets/ucf101/ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi


============================== Final evaluation ==============================
==============================   Train DB   ==============================
original data length 9537
subset data 10 1000
1010 1010
False
UCF-101
 - Root: /home/sdastani/scratch/datasets/ucf101
 - Subset: trainlist01
 - Num videos: 1010
 - Num samples: 10100
 - Example video: /home/sdastani/scratch/datasets/ucf101/ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c03.avi

==============================   Test DB   ==============================
False
UCF-101
 - Root: /home/sdastani/scratch/datasets/ucf101
 - Subset: testlist01
 - Num videos: 3783
 - Num samples: 18915
 - Example video: /home/sdastani/scratch/datasets/ucf101/ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi

==============================   Dense DB   ==============================
False
UCF-101
 - Root: /home/sdastani/scratch/datasets/ucf101
 - Subset: testlist01
 - Num videos: 3783
 - Num samples: 37830
 - Example video: /home/sdastani/scratch/datasets/ucf101/ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi


test_dense: Epoch 16
/home/sdastani/env3.8/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/sdastani/env3.8/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.
  warnings.warn(msg)
/home/sdastani/env3.8/lib/python3.8/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
2023-05-21 17:14:45.392429 | test_dense [16][   1/1261]	Time 36.272 (36.272)	Data 32.470 (32.470)	Loss 4.6640e+00 (4.6640e+00)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  0.00)
2023-05-21 17:15:24.790071 | test_dense [16][ 100/1261]	Time  0.409 ( 0.757)	Data  0.000 ( 0.464)	Loss 4.6640e+00 (4.6176e+00)	Acc@1   0.00 (  0.00)	Acc@5   0.00 (  3.33)
2023-05-21 17:16:19.976535 | test_dense [16][ 200/1261]	Time  0.398 ( 0.552)	Data  0.000 ( 0.271)	Loss 4.6242e+00 (4.6118e+00)	Acc@1   0.00 (  0.17)	Acc@5   0.00 (  4.67)
2023-05-21 17:17:18.803519 | test_dense [16][ 300/1261]	Time  0.224 ( 0.588)	Data  0.000 ( 0.332)	Loss 4.7011e+00 (4.6285e+00)	Acc@1   0.00 (  0.11)	Acc@5   0.00 (  4.00)
2023-05-21 17:18:16.311293 | test_dense [16][ 400/1261]	Time  3.905 ( 0.575)	Data  3.716 ( 0.330)	Loss 4.7587e+00 (4.6277e+00)	Acc@1   0.00 (  0.08)	Acc@5   0.00 (  3.08)
2023-05-21 17:19:07.582098 | test_dense [16][ 500/1261]	Time  0.241 ( 0.513)	Data  0.000 ( 0.271)	Loss 4.6986e+00 (4.6260e+00)	Acc@1   0.00 (  0.07)	Acc@5   0.00 (  3.73)
2023-05-21 17:20:11.812444 | test_dense [16][ 600/1261]	Time  0.186 ( 0.642)	Data  0.000 ( 0.383)	Loss 4.6291e+00 (4.6339e+00)	Acc@1   0.00 (  0.06)	Acc@5   0.00 (  3.11)
2023-05-21 17:21:08.032401 | test_dense [16][ 700/1261]	Time  0.188 ( 0.562)	Data  0.000 ( 0.310)	Loss 4.6476e+00 (4.6318e+00)	Acc@1   0.00 (  0.05)	Acc@5   0.00 (  2.67)
2023-05-21 17:22:17.985103 | test_dense [16][ 800/1261]	Time  0.552 ( 0.699)	Data  0.000 ( 0.430)	Loss 4.5747e+00 (4.6287e+00)	Acc@1   0.00 (  0.04)	Acc@5   0.00 (  2.79)
2023-05-21 17:23:26.314045 | test_dense [16][ 900/1261]	Time  0.312 ( 0.683)	Data  0.000 ( 0.428)	Loss 4.5935e+00 (4.6261e+00)	Acc@1   0.00 (  0.15)	Acc@5   0.00 (  3.44)
2023-05-21 17:24:36.223439 | test_dense [16][1000/1261]	Time  0.358 ( 0.699)	Data  0.000 ( 0.438)	Loss 4.5321e+00 (4.6223e+00)	Acc@1   0.00 (  0.50)	Acc@5   0.00 (  4.37)
2023-05-21 17:25:33.678645 | test_dense [16][1100/1261]	Time  0.266 ( 0.575)	Data  0.000 ( 0.304)	Loss 4.8066e+00 (4.6210e+00)	Acc@1   0.00 (  0.45)	Acc@5   0.00 (  4.21)
2023-05-21 17:26:27.862774 | test_dense [16][1200/1261]	Time  0.152 ( 0.542)	Data  0.000 ( 0.300)	Loss 4.5767e+00 (4.6289e+00)	Acc@1   0.00 (  0.42)	Acc@5   0.00 (  3.86)
2023-05-21 17:26:45.831565 | test_dense [16][1261/1261]	Time  0.151 ( 0.401)	Data  0.000 ( 0.177)	Loss 4.4849e+00 (4.6256e+00)	Acc@1   0.00 (  0.63)	Acc@5  33.33 (  4.76)

============================== Evaluation done ==============================
Video@1:   0.63
Video@MeanTop1:   0.61
Video@5:   4.76
Video@MeanTop5:   4.72
